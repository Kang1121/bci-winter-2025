# bci-winter-2025

Thanks for the code from [EAV: EEG-Audio-Video Dataset for Emotion Recognition in Conversational Contexts](https://github.com/nubcico/EAV).


We pretrain the each modality using code under folder **Transformer_torch**.

After that, you can run the following:

```
python MultimodalLearning.py
```