# bci-winter-2025

Thanks for the code from [EAV: EEG-Audio-Video Dataset for Emotion Recognition in Conversational Contexts](https://github.com/nubcico/EAV).

First clone the above repository and put our code at the outermost level of the directory.

We use *Dataload_audio.py*, *Dataload_vision.py* and *Dataload_eeg.py* to pretrain the model and save in ./ckpt/*MODEL_NAME*.

```
python MultimodalLearning.py
```